\documentclass[A4]{article}
\usepackage{amsmath,amssymb}
\usepackage[left=4cm, right=4cm]{geometry}
\usepackage{bm}

\DeclareMathOperator*{\grad}{grad}
\DeclareMathOperator*{\Grad}{Grad}
\DeclareMathOperator*{\Div}{Div}
\renewcommand{\div}{\operatorname{div}}
\DeclareMathOperator*{\Hess}{Hess}
\DeclareMathOperator*{\curl}{curl}
\DeclareMathOperator{\Tr}{Tr}

\newtheorem{proof}{Proof}


\makeatletter \renewcommand\d[1]{\ensuremath{%
		\;\mathrm{d}#1\@ifnextchar\d{\!}{}}}
\makeatother

% inner products
\def\onedot{$\mathsurround0pt\ldotp$}
\def\cddot{% two dots stacked vertically
	\mathbin{\vcenter{\baselineskip.67ex
			\hbox{\onedot}\hbox{\onedot}}%
}}

\title{Integration by parts for tensors}
\author{Andrea Brugnoli}
\begin{document}
	\maketitle
	
\section{Differential operators}

The space of all, symmetric and skew-symmetric $d\times d$ matrices are denoted by $\mathbb{M},\, \mathbb{S},\, \mathbb{K}$ respectively. The space of $\mathbb{R}^d$ vectors is denoted by $\mathbb{V}$. $\Omega \subset \mathbb{R}^d$ is an open connected set. For a scalar field $u: \Omega \rightarrow \mathbb{R}$ the gradient is defined as 
\begin{equation*}
\grad(u) =  \nabla u := \begin{pmatrix}
\partial_{x_1} u \dots \partial_{x_d} u \\
\end{pmatrix}^\top.
\end{equation*}
For a vector field $\bm{u}: \Omega \rightarrow \mathbb{V}$, with components $u_i$, the gradient (Jacobian) is defined as
\begin{equation*}
\grad(\bm{u})_{i j}:= (\nabla \bm{u})_{ij} = \partial_{x_i} u_j.
\end{equation*}
The symmetric part of the gradient operator $\mathrm{Grad}$ (i. e. the deformation gradient in continuum mechanics) is thus given by
\begin{equation*}
\Grad(\bm{u}) := \frac{1}{2} \left(\nabla \bm{u} + (\nabla\bm{u})^\top \right) \in \mathbb{S}.
\end{equation*}
The Hessian operator of $u$ is then computed as follows
\begin{equation*}
\Hess(u) = \nabla^2 u = \Grad(\grad(u)),
\end{equation*}
For a tensor field $\bm{U}: \Omega \rightarrow \mathbb{M}$, with components $u_{ij}$, the divergence is a vector, defined column-wise as
\begin{equation*}
\Div(\bm U) = \nabla \cdot \bm{U} := \left( \sum_{i = 1}^d \partial_{x_i} u_{ij} \right)_{j = 1, \dots, d}.
\end{equation*}
The double divergence of a tensor field $\bm{U}$ is then a scalar field defined as
\begin{equation*}
\div(\Div(\bm U)):= \sum_{i = 1}^d \sum_{j = 1}^d \partial_{x_i} \partial_{x_j} u_{ij}.
\end{equation*}

\section{Integration by parts}

Consider a smooth tensor-valued function $\bm{A} \in \mathbb{R}^{d\times d}$ and vector-valued function $\bm{b} \in \mathbb{V}=\mathbb{R}^d$. The following integration by parts formula holds
\begin{equation}\label{eq:intbypartsTens}
\int_{\Omega} \left\{\Div(\bm{A}) \cdot \bm{b} + \bm{A} \cddot \grad(\bm{b}) \right\}  \d{\Omega} = \int_{\Omega} \div(\bm{A} \bm{b}) \d{\Omega} = \int_{\partial\Omega} (\bm{A}^\top \bm{n}) \cdot \bm{b} \d{S},
\end{equation}
where $\bm{n}$ is the outward normal at the boundary and $\d{S}$ the infinitesimal surface.
\begin{proof}
	Consider the components expression of Eq. \eqref{eq:intbypartsTens}
	\begin{equation}
	\begin{aligned}
	\int_{\Omega} \left\{\Div(\bm{A}) \cdot \bm{b} + \bm{A} \cddot \grad(\bm{b}) \right\}  \d{\Omega} &=\int_{\Omega} \sum_{i=1}^{d}\sum_{j = 1}^{d}\left\{(\partial_{x_i}{A}_{ij}){b}_j + {A}_{ij} (\partial_{x_i}{b}_j) \right\}  \d{\Omega}, \\
	&= \int_{\Omega} \sum_{i=1}^{d}\sum_{j = 1}^{d}\partial_{x_i}({A}_{ij} {b}_j) \d{\Omega} = \int_{\Omega} \div(\bm{A} \bm{b}) \d{\Omega}, \\
	&= \int_{\partial\Omega} \sum_{i=1}^{d}\sum_{j = 1}^{d} (n_i A_{ij}) {b}_j \d{S} = \int_{\partial\Omega} (\bm{A}^\top \bm{n}) \cdot \bm{b} \d{S}.
	\end{aligned}
	\end{equation}
\end{proof} 
The previous result can be specialized for symmetric tensor field (see Chapter 1 of book mixed element by Boffi etc 2013). Consider a smooth tensor-valued function $\bm{M} \in \mathbb{S} = \mathbb{R}^{d\times d}_{\text{sym}}$ and vector-valued function $\bm{b} \in \mathbb{V}=\mathbb{R}^d$. Then, it holds
\begin{equation}\label{eq:intbypartsSymTens}
\int_{\Omega} \left\{\Div(\bm{S}) \cdot \bm{b} + \bm{M} \cddot \Grad(\bm{b}) \right\}  \d{\Omega} = \int_{\Omega} \div(\bm{M} \bm{b}) \d{\Omega} = \int_{\partial\Omega} (\bm{M} \, \bm{n}) \cdot  \bm{b} \d{S}.
\end{equation}
\begin{proof}
	Consider the components expression of Eq. \eqref{eq:intbypartsSymTens}
	\begin{equation}
	\int_{\Omega} \left\{\Div(\bm{M}) \cdot \bm{b} + \bm{M} \cddot \Grad(\bm{b}) \right\}  \d{\Omega} =\int_{\Omega} \sum_{i=1}^{d}\sum_{j = 1}^{d}\left\{(\partial_{x_i}{M}_{ij}){b}_j + {M}_{ij} \frac{1}{2}(\partial_{x_i}{b}_j + \partial_{x_j}{b}_i) \right\}  \d{\Omega}, 
	\end{equation}
	The term ${M}_{ij} \frac{1}{2}(\partial_{x_i}{b}_j + \partial_{x_j}{b}_i)$ can be manipulated exploiting the symmetry of the tensor~$\bm{M}$
	\begin{equation}
	\begin{aligned}
	\sum_{i=1}^{d}\sum_{j = 1}^{d} \frac{1}{2}({M}_{ij} \partial_{x_i}{b}_j + {M}_{ij} \partial_{x_j}{b}_i) &=  \sum_{i=1}^{d}\sum_{j = 1}^{d} \frac{1}{2} ({M}_{ij} \partial_{x_i}{b}_j + {M}_{ji} \partial_{x_i}{b}_j), \\
	&=  \sum_{i=1}^{d}\sum_{j = 1}^{d} \frac{1}{2}({M}_{ij} + {M}_{ji}) \partial_{x_i}{b}_j \qquad \text{Since $\bm{M}$ is symmetric}, \\
	&= \sum_{i=1}^{d}\sum_{j = 1}^{d} {M}_{ij} \partial_{x_i}{b}_j= \bm{M} \cddot \grad(\bm{b})
	\end{aligned}
	\end{equation}
	Then it holds
	\begin{equation}
	\int_{\Omega} \left\{\Div(\bm{M}) \cdot \bm{b} + \bm{M} \cddot \Grad(\bm{b}) \right\}  \d{\Omega} = \int_{\Omega} \left\{\Div(\bm{M}) \cdot \bm{b} + \bm{M} \cddot \grad(\bm{b}) \right\}  \d{\Omega}
	\end{equation}
	Using Eq \eqref{eq:intbypartsTens} then
	\begin{equation}
	\begin{aligned}
	\int_{\Omega} \left\{\Div(\bm{M}) \cdot \bm{b} + \bm{M} \cddot \Grad(\bm{b}) \right\}  \d{\Omega} &= \int_{\Omega} \left\{\Div(\bm{M}) \cdot \bm{b} + \bm{M} \cddot \grad(\bm{b}) \right\}  \d{\Omega}, \\
	&= \int_{\partial\Omega} (\bm{M}^\top \bm{n}) \cdot \bm{b} \d{S}, \qquad \text{Since $\bm{M}$ is symmetric}, \\
	&= \int_{\partial\Omega} (\bm{M} \, \bm{n}) \cdot \bm{b} \d{S}.
	\end{aligned}
	\end{equation}
	This concludes the proof.
\end{proof} 
\end{document}